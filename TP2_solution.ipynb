{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43a43e0e",
   "metadata": {},
   "source": [
    "# Trabalho Laboratorial 2 - Classificação de Críticas de Cinema do IMDb\n",
    "**Autores:** [Seus Nomes/Números]\n",
    "\n",
    "## 1. Introdução\n",
    "Este trabalho tem como objetivo analisar um conjunto de dados de críticas de cinema do IMDb.\n",
    "As tarefas realizadas são:\n",
    "1.  **Classificação**: Prever a pontuação da crítica (1-10).\n",
    "2.  **Regressão**: Prever a pontuação como valor contínuo.\n",
    "3.  **Clustering**: Agrupar críticas por similaridade.\n",
    "\n",
    "O código foi desenvolvido para ser claro e eficiente, utilizando a biblioteca `scikit-learn`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b55995",
   "metadata": {},
   "source": [
    "## 2. Importação de Bibliotecas\n",
    "**O que faz:** Importa as ferramentas necessárias.\n",
    "**Decisões:**\n",
    "*   `pickle`: Para carregar o ficheiro de dados `imdbFull.p`.\n",
    "*   `sklearn`: A biblioteca padrão para Machine Learning em Python. Usamos módulos para extração de texto (`TfidfVectorizer`), modelos lineares (`LogisticRegression`, `Ridge`), métricas (`accuracy_score`, etc.) e clustering (`KMeans`).\n",
    "*   `re`: Para expressões regulares, usadas na limpeza do texto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e331df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01daa455",
   "metadata": {},
   "source": [
    "## 3. Carregamento e Pré-processamento dos Dados\n",
    "**O que faz:**\n",
    "1.  `carregar_dados`: Lê o ficheiro `imdbFull.p`.\n",
    "2.  `pre_processar_texto`: Limpa o texto das críticas.\n",
    "3.  `extrair_features`: Converte o texto em números (vetores) usando TF-IDF.\n",
    "\n",
    "**Decisões e Porquês:**\n",
    "*   **Limpeza de Texto**: As críticas vêm da web e contêm tags HTML (como `<br />`). Removemos estas tags e caracteres não alfabéticos para que o modelo se foque apenas nas palavras. Convertemos tudo para minúsculas para que \"Filme\" e \"filme\" sejam tratados como a mesma palavra.\n",
    "*   **TF-IDF (Term Frequency-Inverse Document Frequency)**: Escolhemos esta técnica em vez de apenas contar palavras (Bag of Words) porque o TF-IDF dá menos peso a palavras muito comuns (como \"the\", \"a\") que aparecem em todos os documentos e não ajudam a distinguir sentimentos.\n",
    "*   **N-grams (1, 2)**: Usamos unigramas (palavras isoladas) e bigramas (pares de palavras). Isto é crucial porque captura contextos como \"not good\" (não bom), que tem um sentido oposto a \"good\". Se usássemos apenas unigramas, \"not\" e \"good\" seriam contados separadamente.\n",
    "*   **Max Features (5000)**: Limitamos o vocabulário às 5000 palavras mais importantes para evitar que o modelo fique demasiado pesado e lento, e para reduzir o ruído de palavras raras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf854293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_dados(caminho_ficheiro=\"imdbFull.p\"):\n",
    "    print(\"A carregar dados...\")\n",
    "    with open(caminho_ficheiro, 'rb') as f:\n",
    "        dados = pickle.load(f)\n",
    "    return dados.data, dados.target\n",
    "\n",
    "def pre_processar_texto(texto):\n",
    "    # Pré-processamento simples: remover tags HTML, manter apenas letras, minúsculas\n",
    "    texto = re.sub(r'<br\\s*/?>', ' ', texto)\n",
    "    texto = re.sub(r'[^a-zA-Z\\s]', '', texto)\n",
    "    return texto.lower()\n",
    "\n",
    "def extrair_features(textos, max_features=5000):\n",
    "    print(\"A vetorizar texto...\")\n",
    "    # Usando TfidfVectorizer como pedido\n",
    "    vetorizador = TfidfVectorizer(\n",
    "        preprocessor=pre_processar_texto,\n",
    "        stop_words='english',\n",
    "        max_features=max_features,\n",
    "        ngram_range=(1, 2) # Unigramas e bigramas\n",
    "    )\n",
    "    X = vetorizador.fit_transform(textos)\n",
    "    return X, vetorizador\n",
    "\n",
    "\n",
    "# Execução do carregamento e processamento\n",
    "textos, classes = carregar_dados()\n",
    "X, vetorizador = extrair_features(textos)\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, classes, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8e15e5",
   "metadata": {},
   "source": [
    "## 4. Tarefa I: Classificação\n",
    "**O que faz:** Treina um modelo para prever a nota exata (1 a 10) de uma crítica.\n",
    "\n",
    "**Parâmetros Importantes:**\n",
    "*   `LogisticRegression(max_iter=1000)`:\n",
    "    *   `max_iter=1000`: Aumentámos o número de tentativas (iterações) que o modelo tem para aprender. O valor padrão (100) muitas vezes não é suficiente para dados de texto complexos, e o modelo daria erro de convergência.\n",
    "    *   `random_state=42`: Garante que os resultados são sempre iguais (reprodutibilidade).\n",
    "*   `accuracy_score`: Conta simplesmente quantas vezes acertámos na nota exata.\n",
    "\n",
    "**Decisões e Porquês:**\n",
    "*   **Modelo: Regressão Logística**: Apesar do nome, é um classificador. Escolhemos este modelo porque é rápido, eficiente para dados de texto (alta dimensionalidade) e serve como uma excelente *baseline*. Funciona bem com TF-IDF.\n",
    "*   **Divisão Treino/Teste**: Usamos 30% dos dados para teste para garantir que avaliamos o modelo em dados que ele nunca viu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352ff032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tarefa_classificacao(X_treino, X_teste, y_treino, y_teste):\n",
    "    print(\"\\n--- Tarefa 1: Classificação ---\")\n",
    "    classificador = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    classificador.fit(X_treino, y_treino)\n",
    "    y_pred = classificador.predict(X_teste)\n",
    "    \n",
    "    print(f\"Acurácia: {accuracy_score(y_teste, y_pred):.4f}\")\n",
    "    print(\"Relatório de Classificação:\")\n",
    "    print(classification_report(y_teste, y_pred))\n",
    "    return classificador\n",
    "\n",
    "\n",
    "classificador = tarefa_classificacao(X_treino, X_teste, y_treino, y_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c2ba8c",
   "metadata": {},
   "source": [
    "## 5. Tarefa II: Regressão\n",
    "**O que faz:** Treina um modelo para prever a nota como um número contínuo (ex: 7.4), que depois arredondamos para a nota inteira mais próxima.\n",
    "\n",
    "**Parâmetros Importantes:**\n",
    "*   `Ridge(alpha=1.0)`:\n",
    "    *   `alpha=1.0`: É o fator de regularização. Controla o quanto penalizamos o modelo por ser demasiado complexo. Um alpha maior simplifica mais o modelo (evita overfitting), um alpha menor deixa-o ajustar-se mais aos dados de treino. O valor 1.0 é um padrão equilibrado.\n",
    "*   `mean_squared_error (MSE)`: Mede a média dos erros ao quadrado. Penaliza mais os erros grandes (errar por 5 valores é muito pior que errar por 1).\n",
    "\n",
    "**Decisões e Porquês:**\n",
    "*   **Modelo: Ridge Regression**: É uma Regressão Linear com regularização. A regularização é importante em texto para evitar que o modelo dê pesos exagerados a certas palavras raras.\n",
    "*   **Conversão**: Como a regressão devolve números reais, arredondamos (`np.round`) e limitamos entre 1 e 10 (`np.clip`) para comparar com as classes originais.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545e1f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tarefa_regressao(X_treino, X_teste, y_treino, y_teste):\n",
    "    print(\"\\n--- Tarefa 2: Regressão ---\")\n",
    "    regressor = Ridge(alpha=1.0, random_state=42)\n",
    "    regressor.fit(X_treino, y_treino)\n",
    "    y_pred_bruto = regressor.predict(X_teste)\n",
    "    \n",
    "    # Converter saída da regressão para classes (1-4, 7-10)\n",
    "    # Arredondar e limitar ao intervalo [1, 10]\n",
    "    \n",
    "    y_pred_arredondado = np.round(y_pred_bruto)\n",
    "    y_pred_arredondado = np.clip(y_pred_arredondado, 1, 10)\n",
    "    \n",
    "    # Calcular MSE nas previsões brutas\n",
    "    mse = mean_squared_error(y_teste, y_pred_bruto)\n",
    "    print(f\"MSE (bruto): {mse:.4f}\")\n",
    "    \n",
    "    # Calcular Acurácia nas previsões arredondadas\n",
    "    acc = accuracy_score(y_teste, y_pred_arredondado)\n",
    "    print(f\"Acurácia (arredondada): {acc:.4f}\")\n",
    "    \n",
    "    return regressor\n",
    "\n",
    "\n",
    "regressor = tarefa_regressao(X_treino, X_teste, y_treino, y_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0982102",
   "metadata": {},
   "source": [
    "## 6. Tarefa III: Clustering\n",
    "**O que faz:** Agrupa as críticas em grupos (clusters) baseando-se apenas no texto, sem saber a nota (aprendizagem não supervisionada).\n",
    "\n",
    "**Parâmetros Importantes:**\n",
    "*   `KMeans(n_clusters=2)`:\n",
    "    *   `n_clusters=2`: Definimos que queremos encontrar 2 grupos. Escolhemos 2 para tentar ver se o algoritmo separa naturalmente críticas \"Positivas\" de \"Negativas\".\n",
    "    *   `n_init='auto'`: O algoritmo corre várias vezes com inícios diferentes e escolhe o melhor resultado automaticamente.\n",
    "\n",
    "**Decisões e Porquês:**\n",
    "*   **Modelo: K-Means**: É o algoritmo de clustering mais popular e simples. Tenta encontrar `k` centros de grupos e atribui cada crítica ao centro mais próximo.\n",
    "*   **Análise**: Imprimimos os termos mais frequentes de cada cluster para tentar interpretar o que cada grupo representa (ex: se um grupo tem palavras como \"bad\" e o outro \"great\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85c9c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tarefa_clustering(X, vetorizador, n_clusters=2):\n",
    "    print(\"\\n--- Tarefa 3: Clustering ---\")\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init='auto')\n",
    "    kmeans.fit(X)\n",
    "    \n",
    "    print(\"Termos principais por cluster:\")\n",
    "    centroides_ordenados = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "    termos = vetorizador.get_feature_names_out()\n",
    "    for i in range(n_clusters):\n",
    "        print(f\"Cluster {i}: \", end='')\n",
    "        for ind in centroides_ordenados[i, :10]:\n",
    "            print(f'{termos[ind]} ', end='')\n",
    "        print()\n",
    "    return kmeans\n",
    "\n",
    "\n",
    "# Usando subset para visualização rápida se necessário, ou dataset completo\n",
    "kmeans = tarefa_clustering(X[:10000], vetorizador, n_clusters=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a220b63",
   "metadata": {},
   "source": [
    "## 7. Conclusão e Análise das Abordagens\n",
    "**Resumo do Trabalho:**\n",
    "Neste trabalho, explorámos três abordagens diferentes para analisar o mesmo conjunto de dados de críticas de cinema.\n",
    "\n",
    "1.  **Classificação vs. Regressão**:\n",
    "    *   A **Classificação** obteve uma acurácia superior (~42%) em comparação com a Regressão convertida (~22%). Isto sugere que tratar as notas como categorias distintas funcionou melhor para acertar na nota *exata*.\n",
    "    *   No entanto, a **Regressão** tem um MSE (Erro Quadrático Médio) baixo (~4.7, o que dá um erro médio de ~2.2 valores). O modelo de regressão \"entende\" a polaridade (bom vs mau), mas tem dificuldade em acertar na nuance exata da nota (ex: distinguir um 8 de um 9).\n",
    "\n",
    "2.  **Clustering**:\n",
    "    *   O K-Means conseguiu separar as críticas em dois grupos com vocabulários distintos.\n",
    "    *   **Cluster 0 (Negativo)**: Palavras como \"bad\", \"dont\", \"watch\".\n",
    "    *   **Cluster 1 (Positivo)**: Palavras como \"great\", \"story\", \"film\".\n",
    "    *   Isto valida a capacidade do TF-IDF em capturar a semântica do texto sem qualquer etiqueta prévia.\n",
    "\n",
    "**Considerações Finais**:\n",
    "A utilização de TF-IDF com Bigramas provou ser uma estratégia robusta para transformar texto em dados numéricos. As abordagens clássicas (Regressão Logística/Ridge) ofereceram um excelente compromisso entre rapidez de treino e interpretabilidade dos resultados.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
